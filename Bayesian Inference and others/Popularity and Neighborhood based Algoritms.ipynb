{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Recommender Systems Intro\n",
        "\n",
        "Below are the notes and implementation for some concepts used in builing recommendation algorithms."
      ],
      "metadata": {
        "id": "OCZfJyNTAmRC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Popularity\n",
        "\n",
        "For instance, movies in the  top 10 list of Netflix. \n",
        "\n",
        "Problem - highest popularity does not mean best choice - 0 exploration, full exploitation\n",
        "\n",
        "For instance music platforms, news websites - e.g., Age, location and other factors play important role  "
      ],
      "metadata": {
        "id": "MA-N3muY_T9v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Product associations\n",
        "\n",
        " e.g., Complement products - products that logically go together, context matters in recommendations. - People who buy phone usually also by phone cover, headphones etc.\n",
        "\n",
        " * `Lyft` -  prob that a and b divided by prod of pa and pb\n",
        " $$Lyft = \\frac{Pr(a \\text{ and } b)}{ Pr(a)Pr(b)} = \\frac{Pr(a|b)}{Pr(a)} = \\frac{Pr(b|a)}{Pr(b)}$$ \n",
        "\n",
        " * symmetric metric\n",
        " * if a and b is independent, we get $Lyft = 1$\n",
        " * if buying b increases the likelihood of buying a then lyft>1."
      ],
      "metadata": {
        "id": "2iymeouF_8rR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hacker News\n",
        "\n",
        "* Ratio of popularity to time (age) $$score = \\frac{(ups-downs -1)^{0.8}}{(age+2)^{gravity}} * penalty $$\n",
        "\n",
        "* gravity = 1.8 - how fast the score goes down with age (in hours)\n",
        "\n",
        "* penalty - sets the business rule (for instance, self posts ranked lower than the post containing the link to original source)\n",
        "\n",
        "* popularity follow power law (long tail) - few articles have high votes, and most have fewer votes - so popularity grows sublinearly"
      ],
      "metadata": {
        "id": "H3jiV7qTCLUW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Problems with average Ratings\n",
        "\n",
        "Binary, range ratings \n",
        "\n",
        "Sorting by average rating - we need to be confident in the rating as well. Calculate confidence interval upper and lower bound ---> pessimistic approach use lower bound\n",
        "\n",
        "\n",
        "\n",
        "$$\\bar{X} \\sim N(\\mu, \\frac{\\sigma^2}{N})$$\n",
        "\n",
        "Higher rating count  => narrower confidence interval \n",
        "\n",
        "Even though data does not follow normal distribution, by Central Limit theorem sum of random variables follow normal distribution\n",
        "\n",
        "Binary ratings, we can use Bernoilly distribution. \n",
        "$$ \\hat{p} = \\frac{\\# success}{N}$$\n",
        "$$95CI = [\\hat{p}\\pm 1.96 * \\sqrt{\\frac{\\hat{p}(1-\\hat{p})}{N}}]$$\n",
        "\n",
        "Better to use Wilson confidence interval (read the extra readings file)\n",
        "\n",
        "* zero ratings problem - no average - use smoothing (dampening) by adding a small number to numerator and denominator, or use a medium rating as 3 stars.\n",
        "\n",
        "$$ Score = \\frac{\\sum X + \\mu*\\lambda}{N+\\lambda} $$\n",
        "\n",
        "* The above formula, scales down the review if the number of reviews is smaller. For instance, for $\\lambda = 1$, a product with zero reviews will have mean review initially. A product with very few bad reviews will have higher than the average rating, and a product with very few but good reviews will have a review smaller than average reviews, in other words initially the algorithm keeps the score closer to the average rating until it has enough confidence calculated with many reviews."
      ],
      "metadata": {
        "id": "uD2Ni5PdGIrF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Explore - Exploit dilemma\n",
        "\n",
        "For instance, Good estimate requires more data, and on the other hand more data means more data to spend to do something suboptimal. Suppose that youtube shows you a very similar videos to the ones you watched, but does not show different topic videos. Watching cooking videos will cause the algorithms to recommend more cooking videos. However, if the algorithm recommends a different topic there is a risk that you will not find it interesting.\n"
      ],
      "metadata": {
        "id": "edKfHTMgKBLI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bayesian Ranking\n",
        "\n",
        "Random listing of the items w.r.t underlying distribution. Let us say we list items by click through rate. We can treat CTR as a random number. How to score two distributions : \n",
        "* sample random numbers - Thompson Sampling \n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_GKfrchOMRQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### PageRank Algorithm\n",
        "\n",
        "Prob that you will end up on a page if you surf on the internet randomly for the infinite amount of time.\n",
        "\n",
        "Markov Models -- what is the probability that new page is x given that the current page is y. The next page depends on only the current page..\n",
        "\n",
        "Consider page as a state at time t - $Pr(X_{t+1} | X_t)$\n",
        "\n",
        "Transition matrix - probability of going one state to another $A_{i,j} = Pr(x_t = j| x_{t-1} = i)$. $$ \\sum_{j=1}^M A_{ij} = \\sum_{j=1}^M Pr(x_t = j| x_{t-1} =i) =1 $$.\n",
        "\n",
        "Key point is that sum of transition probabilities in the same row must be 1. \n",
        "\n",
        "Example : Weather sunny and rainy day - from sunny to sunny or rainy, from rainty to sunny or rainy.\n",
        "$Pr(sunny|rainy) = \\frac{count(rainty->sunny)}{count(rainty)}$\n",
        "\n",
        "Add one smoothing to avoid getting 0 probability if not observed rainy->sunny\n",
        "\n",
        "* State distribution: $\\pi^t =$ state probability distribution at time $t$.\n",
        "\n",
        "Probability of being in a state at time $t$. Consider it as a row vector of state probabilities.$$\\pi^{t+n} = \\pi^{t}*A^n\\\\\n",
        "pi^\\infty = \\lim_{t\\to\\infty}\\pi_0A^t = \\pi^\\infty A\\\\\n",
        "\\pi = \\pi A$$ where $\\pi$ is the limiting probability distribution. \n",
        "This is just the eigen value problem. Matrix and a vector and a number : multiplying matrix by a vector is equal to vector by a number. -- multiplying vector by a matrix will not change its direction but magnitude $Av = \\lambda v $.\n",
        "\n",
        "The problem $\\pi = \\pi A$ is the same as eigen value problem where eigen value is one. The difference is that state distribution is a row vector hence it is on the left rather than on the right as in the eigen vector formula.\n",
        "\n",
        "So think of the pages as the states, and we can calculate transition probs between the pages that all the links apper on the page (equal prob: $1/n_{i}$). Since there are million of pages, the matrix will be a sparse matrix. So we will smooth the the probs. $G = 0.85*A + 0.15U$ where $A$ is the transition matrix and $U$ is the similar matrix where $U_{i,j} = 1/M$"
      ],
      "metadata": {
        "id": "1XzBYi52le-e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating Recommendations\n",
        "\n",
        "Interested in returning the list with highest ranking at the top and lowest at the bottom: [wiki](https://en.wikipedia.org/wiki/Learning_to_rank#Evaluation_measures)\n",
        "\n",
        "More realistic: Revenues - which is related to clicks and impressions. (Deploy and evaluate) A/B test."
      ],
      "metadata": {
        "id": "8CyDGc4vuEDA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Collaborative filtering\n",
        "\n",
        "$s_{i,j}$ is the rating of item $j$ for user $i$. If we use thea average rating weighted by the user-user similarity vectors, we would use $$ s_{i,j} = \\frac{\\sum_{i'\\inΩ_j}w_{i,i'}r_{i',j}}{\\sum_{i'\\in\\Omega_j} w_{i,i'}} $$.\n",
        "\n",
        "where $r_{i,j}$ is an element of $R_{NxM}$ which is a sparse user-item matrix. Sparsity means most of the elements is missing or empty. The goal is to predict the missing elements/ratings and recommending the highest rating items to the user.\n",
        "\n",
        "$$MSE = \\frac{1}{\\Omega} \\sum_{i,j\\in Ω}(r_{i,j}-\\hat{r}_{i,j})^2$$\n",
        "\n",
        "Users may be pessimistic or optimistic - tend to give smaller or higher ratings. (how much user rating deviates from his/her rating).\n",
        "$$dev_{i,j} = r_{i,j} - \\bar{r}\\text{  For known ratings}\\\\\n",
        "\\hat{dev_{i,j}} = \\frac{1}{\\Omega_{i'}}\\frac{\\sum_{i'\\in \\Omega_j}w_{i,i'}(r_{i',j}-\\bar{r}_i')}{\\sum_{i'\\in \\Omega_j}|w_{i,i'}|}\\text{  For a prediction from known ratings}\\\\\n",
        "\\hat{s_{i,j}} = \\bar{r_i}+\\hat{dev_{i,j}}$$\n",
        "\n",
        "Simple way to predict similarity weights $w_{i,i'}$ is to use cosine similarity or pearson similarities. \n",
        "\n",
        "To make the calculations faster, we can only consider the k-nearest neighbors, or we can ignore the users with only small number of ratings."
      ],
      "metadata": {
        "id": "qtYiZutUKjYy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing\n",
        "\n",
        "The [data](https://www.kaggle.com/datasets/grouplens/movielens-20m-dataset?select=rating.csv) has 20M rows. Each row contains user id, movie id, and a rating between 0 and 5. The goal is to get the data into user item matrix format."
      ],
      "metadata": {
        "id": "NOZ6dIqNMdVo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "zipref = zipfile.ZipFile('movielens_ratings.zip')\n",
        "zipref.extractall()\n",
        "zipref.close()"
      ],
      "metadata": {
        "id": "Eoyh7PMl_8Cr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qeggv5xE-NCW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1c4a7f6c-9640-4ef9-bd30-d73fc6d33e30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   userId  movieId  rating            timestamp\n",
              "0       1        2     3.5  2005-04-02 23:53:47\n",
              "1       1       29     3.5  2005-04-02 23:31:16\n",
              "2       1       32     3.5  2005-04-02 23:33:39\n",
              "3       1       47     3.5  2005-04-02 23:32:07\n",
              "4       1       50     3.5  2005-04-02 23:29:40"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c3eb9fc-4b64-46f0-b429-1b196744b764\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>userId</th>\n",
              "      <th>movieId</th>\n",
              "      <th>rating</th>\n",
              "      <th>timestamp</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:53:47</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>29</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:31:16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>32</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:33:39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:32:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2005-04-02 23:29:40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c3eb9fc-4b64-46f0-b429-1b196744b764')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c3eb9fc-4b64-46f0-b429-1b196744b764 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c3eb9fc-4b64-46f0-b429-1b196744b764');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "ratings = pd.read_csv('rating.csv')\n",
        "ratings.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get user and movie counts\n",
        "N = ratings.userId.nunique()\n",
        "M = ratings.movieId.nunique()\n",
        "\n",
        "print(f'There are {ratings.shape[0]} ratings in the data')\n",
        "print(f'There are {N} users')\n",
        "print(f'Max and Min user Ids are {ratings.userId.max()}, {ratings.userId.min()}')\n",
        "print(f'There are {M} movies')\n",
        "print(f'Max and Min movie Ids are {ratings.movieId.max()}, {ratings.movieId.min()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6V-5IxwoNI64",
        "outputId": "f80a5590-84d3-4544-8933-a75f923e06a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 20000263 ratings in the data\n",
            "There are 138493 users\n",
            "Max and Min user Ids are 138493, 1\n",
            "There are 26744 movies\n",
            "Max and Min movie Ids are 131262, 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "user_ids_count = Counter(ratings.userId)\n",
        "movie_ids_count = Counter(ratings.movieId)\n",
        "\n",
        "# number of users and movies we would like to keep\n",
        "n = 10000\n",
        "m = 2000\n",
        "\n",
        "user_ids = [u for u, c in user_ids_count.most_common(n)]\n",
        "movie_ids = [m for m, c in movie_ids_count.most_common(m)]"
      ],
      "metadata": {
        "id": "pToProEjhjAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the subset of ratings data with n users and m movies\n",
        "subset = ratings[(ratings.movieId.isin(movie_ids))&(ratings.userId.isin(user_ids))]\n",
        "subset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8w88UP6Sr10",
        "outputId": "92aa0344-d347-417c-ef9b-adf801f5ffb2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5392025, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create user and movies dictionaries\n",
        "user_index = {i:j for j,i in enumerate(user_ids)}\n",
        "movie_index = {i:j for j,i in enumerate(movie_ids)}"
      ],
      "metadata": {
        "id": "ko5sdo6cUqoh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test sets \n",
        "from sklearn.model_selection import train_test_split\n",
        "train, test = train_test_split(subset, test_size = 0.2, shuffle = True)\n",
        "train.shape, test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNUEsET5a0T7",
        "outputId": "9e7c4524-662f-4bb4-adc7-17a74e55b8c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4313620, 4), (1078405, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Build the ranking by user-user similarities"
      ],
      "metadata": {
        "id": "NeailGJMupWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We want to calculate the following formula for the users. $$\\hat{dev_{i,j}} = \\frac{\\sum_{i'\\in \\Omega_j}w_{i,i'}(r_{i',j}-\\bar{r}_i')}{\\sum_{i'\\in \\Omega_j}|w_{i,i'}|}\\text{  For a prediction from known ratings}\\\\\n",
        "\\hat{s_{i,j}} = \\bar{r_i}+\\hat{dev_{i,j}}$$\n",
        "* Steps:\n",
        "1. Fill in the user-item matrix using train set (it would be better to use sparse matrix, but since I am working with a smaller subset, it is not necessary)\n",
        "2. Calculate user similarity matrix\n",
        "3. Calculate user average rating and scale the ratings -> rating deviance\n",
        "4. Calculate the score formula"
      ],
      "metadata": {
        "id": "U5HxSTD6eOOE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create User-Item matrix\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "user_item_matrix = np.zeros(shape = (n,m))\n",
        "for row in tqdm(train.values):\n",
        "  user_item_matrix[user_index[row[0]], movie_index[row[1]]] = row[2]\n",
        "user_item_matrix.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tw64A7CnaiWh",
        "outputId": "2a61c616-bddf-4ff8-9883-df4559066b38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4313620/4313620 [00:07<00:00, 562213.53it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the average user rating and shift ratings\n",
        "user_average  = np.sum(user_item_matrix, axis = 1, keepdims = True)/np.sum(user_item_matrix!=0, axis = 1, keepdims = True)\n",
        "print(user_average.shape, user_average.min(), user_average.max())\n",
        "user_item_matrix_scaled = np.where(user_item_matrix!=0, user_item_matrix - user_average,0)\n",
        "print(user_item_matrix_scaled.shape, user_item_matrix_scaled.min(), user_item_matrix_scaled.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzgZMTvidchf",
        "outputId": "7fdcb627-3a09-4f68-b0c8-79b02a7f0bba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 1) 1.132034632034632 4.927007299270073\n",
            "(10000, 2000) -4.074534161490683 3.6674107142857144\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Calculate cosine similarity between users\n",
        "user_similarity = cosine_similarity(user_item_matrix_scaled)"
      ],
      "metadata": {
        "id": "tQB2Lad3Tijm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a similarity mask (will ignore similarity if the number of movies rated by both users is less than a cutoff value)\n",
        "mask = (user_item_matrix_scaled!=0).astype('float32')\n",
        "masked_similarity = mask@mask.T"
      ],
      "metadata": {
        "id": "t0rHN2w5gZKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate weighted score matrix using top similar users\n",
        "user_similarity_norm = user_similarity.copy()\n",
        "user_similarity_norm = np.where(masked_similarity<5, 0, user_similarity_norm) # keep most confident similarities\n",
        "\n",
        "# Select top k similar users\n",
        "k = 25\n",
        "top_indices = np.argpartition(user_similarity_norm, -k, axis=1)[:, -k:]\n",
        "\n",
        "# Set the other values to zero in place\n",
        "for i in range(n):\n",
        "    not_top_indices = np.delete(np.arange(n), top_indices[i])\n",
        "    user_similarity_norm[i, not_top_indices] = 0\n",
        "\n",
        "# diagonal values are not useful for making recommendations\n",
        "for i in range(n):\n",
        "  user_similarity[i,i]=0 \n",
        "\n",
        "# Scale the weights to sum up to 1\n",
        "user_similarity_sum = user_similarity_norm.sum(axis=1) # get row sum\n",
        "user_similarity_sum[user_similarity_sum == 0] = 1 # if zero set to 1 to avoid division by zero\n",
        "user_similarity_norm /= user_similarity_sum[:, np.newaxis]  # divide by sum to get similarity weights\n",
        "user_similarity_norm.shape, user_similarity_norm.max(), user_similarity_norm.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "26436-rSK2Nt",
        "outputId": "db789682-b09c-45d7-b28a-8b7d6cf5ed7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 10000), 0.3846965212388212, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del top_indices\n",
        "del user_similarity_sum\n",
        "del subset\n",
        "del ratings\n",
        "del user_ids_count\n",
        "del movie_ids_count\n",
        "del user_ids\n",
        "del movie_ids"
      ],
      "metadata": {
        "id": "3MF5NODczKWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the score matrix\n",
        "score_matrix = np.matmul(user_similarity_norm, user_item_matrix_scaled) + user_average  # get rating predictions using similar user ratings\n",
        "score_matrix = np.where(score_matrix<0.5, 0.5, score_matrix)  # ratings range between 0.5 and 5 - if interested in ranking then no need to truncate\n",
        "score_matrix = np.where(score_matrix>5, 5, score_matrix) \n",
        "score_matrix.shape, score_matrix.max().max(), score_matrix.min().min() # confirm the score range"
      ],
      "metadata": {
        "id": "uDI0KHy_zdRr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4c91351-5960-4cd2-aa9b-d32781b0ad03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 2000), 5.0, 0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del user_similarity\n",
        "del user_similarity_norm"
      ],
      "metadata": {
        "id": "rAg4Fq440RAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict test data \n",
        "user_preds = []\n",
        "for row in test.values:\n",
        "  user_preds.append(score_matrix[user_index[row[0]], movie_index[row[1]]])"
      ],
      "metadata": {
        "id": "jlFmBt3cMs_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Mae for test data\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "mean_absolute_error(test.rating.values, user_preds) , mean_squared_error(test.rating.values, user_preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TtUtAcmwMtCL",
        "outputId": "d888c90b-e505-4bc4-c90f-7ee48581ce5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6322528683102926, 0.6813177292335322)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Item-Item Collaborative filtering"
      ],
      "metadata": {
        "id": "-rregek1miG-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create User-Item matrix\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "user_item_matrix = np.zeros(shape = (m,n))\n",
        "for row in tqdm(train.values):\n",
        "  user_item_matrix[movie_index[row[1]], user_index[row[0]]] = row[2]\n",
        "print(user_item_matrix.shape)\n",
        "\n",
        "# Calculate the average movie rating\n",
        "movie_average = np.sum(user_item_matrix, axis = 1, keepdims = True)/np.sum(user_item_matrix!=0, axis = 1, keepdims = True)\n",
        "print(movie_average.shape, movie_average.min(), movie_average.max())\n",
        "\n",
        "# Scale the matrix\n",
        "user_item_matrix_scaled = np.where(user_item_matrix!=0, user_item_matrix - movie_average,0)\n",
        "print(user_item_matrix_scaled.shape, user_item_matrix_scaled.min(), user_item_matrix_scaled.max())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHHSMhn3mhmi",
        "outputId": "ba1e4b41-b8cd-44f3-9dd7-76179413007b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4313620/4313620 [00:08<00:00, 505120.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2000, 10000)\n",
            "(2000, 1) 1.4895031490552835 4.39356022689356\n",
            "(2000, 10000) -3.89356022689356 3.5104968509447163\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "# Calculate cosine similarity between users\n",
        "movie_similarity = cosine_similarity(user_item_matrix_scaled)"
      ],
      "metadata": {
        "id": "EyBr43UioQ3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a similarity mask (will ignore similarity if the number of movies rated by both users is less than a cutoff value)\n",
        "mask = (user_item_matrix_scaled!=0).astype('float32')\n",
        "masked_similarity = mask@mask.T<5\n",
        "\n",
        "# Calculate weighted score matrix using top similar users\n",
        "movie_similarity_norm = movie_similarity.copy()\n",
        "movie_similarity_norm = np.where(masked_similarity, 0, movie_similarity_norm) # keep most confident similarities\n",
        "\n",
        "# Select top 100 similar movies\n",
        "k = 25\n",
        "top_indices = np.argpartition(movie_similarity_norm, -k, axis=1)[:, -k:]\n",
        "\n",
        "# Set the other values to zero in place\n",
        "for i in range(m):\n",
        "    not_top_indices = np.delete(np.arange(m), top_indices[i])\n",
        "    movie_similarity_norm[i, not_top_indices] = 0\n",
        "\n",
        "# diagonal values are not useful for making recommendations\n",
        "for i in range(m):\n",
        "  movie_similarity_norm[i,i]=0 \n",
        "\n",
        "# Scale the weights to sum up to 1\n",
        "movie_similarity_sum = movie_similarity_norm.sum(axis=1)\n",
        "movie_similarity_sum[movie_similarity_sum == 0] = 1\n",
        "movie_similarity_norm /= movie_similarity_sum[:, np.newaxis]\n",
        "movie_similarity_norm.shape, movie_similarity_norm.max(), movie_similarity_norm.min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RkPu4bTvm3nY",
        "outputId": "edda56ae-10c8-40e4-c7e0-ab4be0cc7e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2000, 2000), 0.16309781562664033, 0.0)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the score matrix\n",
        "score_matrix = np.matmul(movie_similarity_norm, user_item_matrix_scaled) + movie_average\n",
        "score_matrix = np.where(score_matrix<0.5, 0.5, score_matrix)\n",
        "score_matrix = np.where(score_matrix>5, 5, score_matrix)\n",
        "score_matrix.shape, score_matrix.max().max(), score_matrix.min().min()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0jbGt1UxoKIZ",
        "outputId": "faeb9973-1aa5-45cb-d4a6-b3e85cc30a4f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2000, 10000), 5.0, 0.5)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Predict test data \n",
        "preds = []\n",
        "for row in test.values:\n",
        "  preds.append(score_matrix[movie_index[row[1]],user_index[row[0]]])\n",
        "  \n",
        "# Mae for test data\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "mean_absolute_error(test.rating.values, preds) , mean_squared_error(test.rating.values, preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDQp5MbPoecZ",
        "outputId": "f9a66ac1-408d-4887-8f15-c91f3f42c9b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6019839345947412, 0.6163038410564982)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Item-item recommender performs better than user-user recommender because we have relatively less movies than users, so we have more values to find accurate similarities between movies."
      ],
      "metadata": {
        "id": "56Taov4k-3go"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the weighted rating predictions using user2user and movie2movie predictions\n"
      ],
      "metadata": {
        "id": "4NfogePNuKBf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the weight that results in the lowest mean absolute error\n",
        "threshold = np.linspace(0.2, 0.9, 30)\n",
        "errors = []\n",
        "lowest_error = 100\n",
        "best_threshold = 0\n",
        "for i in threshold:\n",
        "  mean_preds = ((1-i)*np.array(user_preds)+i*np.array(preds))\n",
        "  error = mean_absolute_error(test.rating.values, mean_preds)\n",
        "  if error<lowest_error:\n",
        "    best_threshold = i\n",
        "    lowest_error = error\n",
        "print(best_threshold, lowest_error)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xQRxP6wop9i",
        "outputId": "d46a7a66-529c-4fcc-8a4a-b13e18715e1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7310344827586206 0.5969067126717832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lozURyOopnfM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}